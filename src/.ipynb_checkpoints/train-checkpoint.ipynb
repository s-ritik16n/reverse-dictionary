{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "defs = pd.read_csv(\"db/sample/clean/def_col_vectors.csv\", names=[\"word\", \"word_vector\",\"definition\", \"def_vectors\"], sep=\":\", index_col=None, keep_default_na=False, na_values=[\"\"])\n",
    "word_list = pd.read_csv(\"db/sample/clean/word_col_vectors.csv\", names=[\"word\", \"word_vector\"], sep=\":\", index_col=None, keep_default_na=False, na_values=[\"\"])\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "defs = defs.values.tolist()\n",
    "word_list = word_list.values.tolist()\n",
    "defs_main = defs[:6575]\n",
    "\n",
    "defs_main = [[str(d[0]).strip(), d[1], str(d[2]).strip(), str(d[3]).strip()] for d in defs_main]\n",
    "size = len(word_list)\n",
    "\n",
    "for n in defs_main:\n",
    "    main_word = str(n[0])\n",
    "    definition = str(n[2]).split()\n",
    "    vector = str(n[3]).split()\n",
    "    out = np.zeros((size,), dtype=int)\n",
    "    inp = np.zeros((size,), dtype=int)\n",
    "    for word in word_list:\n",
    "        if word[0] is main_word:\n",
    "            out[word[1]] = 1\n",
    "        if word[0] in definition:\n",
    "            inp[word[1]] = 1\n",
    "    X.append(inp)\n",
    "    y.append(out)\n",
    "\n",
    "    \n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if arrays contain desired value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_found(array, val):\n",
    "    flag = False\n",
    "    for arr in array:\n",
    "        for a in arr:\n",
    "            if a != val:\n",
    "                print(a)\n",
    "                print(\"found\")\n",
    "                flag = True\n",
    "                break\n",
    "        if flag:\n",
    "            break\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "check_if_found(X,0)\n",
    "check_if_found(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ritiksax\\AppData\\Local\\Continuum\\miniconda3\\envs\\revdict\\lib\\site-packages\\ipykernel\\__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return np.around(1/(1+np.exp(-x)), decimals=30)\n",
    "\n",
    "def der_sigmoid(x):\n",
    "    return 1*(1-x)\n",
    "\n",
    "epoch=20\n",
    "lr=0.1\n",
    "\n",
    "input_layer_neurons = X.shape[1] # 3\n",
    "hiddenlayer_neurons = 3\n",
    "output_neurons = size\n",
    "\n",
    "wh = np.random.uniform(size = (input_layer_neurons, hiddenlayer_neurons))\n",
    "bh = np.random.uniform(size = (1, hiddenlayer_neurons))\n",
    "wout = np.random.uniform(size = (hiddenlayer_neurons, output_neurons))\n",
    "bout = np.random.uniform(size = (1, output_neurons))\n",
    "\n",
    "for i in range(epoch):\n",
    "    # Forward propagation\n",
    "    hidden_layer_input1 = np.dot(X,wh)\n",
    "    hidden_layer_input = hidden_layer_input1 + bh\n",
    "    hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "    output_layer_input1 = np.dot(hidden_layer_activations, wout)\n",
    "    output_layer_input = output_layer_input1 + bout\n",
    "    output = sigmoid(output_layer_input)\n",
    "\n",
    "    # Backpropagation\n",
    "    E = y-output\n",
    "    slope_output_layer = der_sigmoid(output)\n",
    "    slope_hidden_layer = der_sigmoid(hidden_layer_activations)\n",
    "    d_output = E * slope_output_layer\n",
    "    Error_at_hidden_layer = d_output.dot(wout.T)\n",
    "    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "    wout += hidden_layer_activations.T.dot(d_output) * lr\n",
    "    bout += np.sum(d_output, axis=0, keepdims = True) * lr\n",
    "    wh += X.T.dot(d_hiddenlayer) * lr\n",
    "    bh += np.sum(d_hiddenlayer, axis=0, keepdims = True) * lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pkl-db/wh.pkl\",\"wb\") as f:\n",
    "    pickle.dump(wh,f)\n",
    "\n",
    "with open(\"pkl-db/bh.pkl\",\"wb\") as f:\n",
    "    pickle.dump(bh,f)\n",
    "\n",
    "with open(\"pkl-db/wout.pkl\",\"wb\") as f:\n",
    "    pickle.dump(wout,f)\n",
    "\n",
    "with open(\"pkl-db/bout.pkl\",\"wb\") as f:\n",
    "    pickle.dump(bout,f)\n",
    "\n",
    "with open(\"pkl-db/output.pkl\",\"wb\") as f:\n",
    "    pickle.dump(output,f)\n",
    "\n",
    "with open(\"pkl-db/X.pkl\",\"wb\") as f:\n",
    "    pickle.dump(X,f)\n",
    "\n",
    "with open(\"pkl-db/y.pkl\",\"wb\") as f:\n",
    "    pickle.dump(y,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if data is saved correctly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9346699565064474\n",
      "found\n",
      "-18879.739124911714\n",
      "found\n",
      "-38.465961730243265\n",
      "found\n",
      "-40.034687716883006\n",
      "found\n",
      "4.1e-18\n",
      "found\n",
      "1\n",
      "found\n",
      "1\n",
      "found\n"
     ]
    }
   ],
   "source": [
    "with open(\"pkl-db/wh.pkl\",\"rb\") as f:\n",
    "    whpkl = pickle.load(f)\n",
    "    check_if_found(whpkl,0)\n",
    "    \n",
    "with open(\"pkl-db/bh.pkl\",\"rb\") as f:\n",
    "    bhpkl = pickle.load(f)\n",
    "    check_if_found(bhpkl,0)\n",
    "    \n",
    "with open(\"pkl-db/wout.pkl\",\"rb\") as f:\n",
    "    woutpkl = pickle.load(f)\n",
    "    check_if_found(woutpkl,0)\n",
    "    \n",
    "with open(\"pkl-db/bout.pkl\",\"rb\") as f:\n",
    "    boutpkl = pickle.load(f)\n",
    "    check_if_found(boutpkl,0)\n",
    "    \n",
    "with open(\"pkl-db/output.pkl\",\"rb\") as f:\n",
    "    outputpkl = pickle.load(f)\n",
    "    check_if_found(outputpkl,0.5)\n",
    "    \n",
    "with open(\"pkl-db/X.pkl\",\"rb\") as f:\n",
    "    Xpkl = pickle.load(f)\n",
    "    check_if_found(Xpkl,0)\n",
    "    \n",
    "with open(\"pkl-db/y.pkl\",\"rb\") as f:\n",
    "    ypkl = pickle.load(f)\n",
    "    check_if_found(ypkl,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_revdict)",
   "language": "python",
   "name": "conda_revdict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
